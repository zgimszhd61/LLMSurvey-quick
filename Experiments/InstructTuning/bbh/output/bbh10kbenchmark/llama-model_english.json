[{"question": "Evaluate the result of a random Boolean expression.\n\nQ: True and ( not True or False ) is\nA: ", "answer": "False", "taskname": "boolean_expressions", "type": "complex", "response": "The result of the random Boolean expression is \"True\"."}, {"question": "Order adjectives correctly in English sentences.\n\nQ: Which sentence has the correct adjective order:\nOptions:\n(A) repulsive old-fashioned rectangular green Japanese exercise ship\n(B) rectangular exercise green old-fashioned Japanese repulsive ship\nA: ", "answer": "(A)", "taskname": "hyperbaton", "type": "linguistic", "response": "(A) repulsive old-fashioned rectangular green Japanese exercise ship"}, {"question": "Name geometric shapes from their SVG paths.\n\nQ: This SVG path element <path d=\"M 64.00,63.00 L 36.00,63.00 L 36.00,50.00 L 64.00,50.00 L 64.00,45.00 L 85.00,57.00 L 64.00,68.00 L 64.00,63.00\"/> draws a\nOptions:\n(A) circle\n(B) heptagon\n(C) hexagon\n(D) kite\n(E) line\n(F) octagon\n(G) pentagon\n(H) rectangle\n(I) sector\n(J) triangle\nA: ", "answer": "(B)", "taskname": "geometric_shapes", "type": "mathematical", "response": "(A) circle"}, {"question": "A logical deduction task which requires deducing the order of a sequence of objects.\n\nQ: The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. In an antique car show, there are five vehicles: a station wagon, a tractor, a truck, a hatchback, and a minivan. The station wagon is newer than the tractor. The truck is older than the tractor. The minivan is newer than the hatchback. The hatchback is the second-newest.\nOptions:\n(A) The station wagon is the second-oldest\n(B) The tractor is the second-oldest\n(C) The truck is the second-oldest\n(D) The hatchback is the second-oldest\n(E) The minivan is the second-oldest\nA: ", "answer": "(B)", "taskname": "logical_deduction_five_objects", "type": "complex", "response": "The minivan is the second-oldest."}, {"question": "Select the humorous edit that 'ruins' the input movie or musical artist name.\n\nQ: Which of the following is a humorous edit of this artist or movie name: 'killing joke'?\nOptions:\n(A) killing toke\n(B) killing jokes\n(C) killing coke\n(D) villing joke\nA: ", "answer": "(A)", "taskname": "ruin_names", "type": "humanoid", "response": "(A) killing toke"}, {"question": "Evaluate a random boolean function expressed as a word problem.\n\nQ: Question: Alejandro lies. Vina says Alejandro lies. Vernell says Vina tells the truth. Fidel says Vernell lies. Inga says Fidel tells the truth. Does Inga tell the truth?\nA: ", "answer": "No", "taskname": "web_of_lies", "type": "complex", "response": "No, Inga does not tell the truth in this scenario."}, {"question": "Name geometric shapes from their SVG paths.\n\nQ: This SVG path element <path d=\"M 32.43,11.23 L 25.24,31.00 M 25.24,31.00 A 21.04,21.04 298.07 0,1 11.90,15.87 L 32.43,11.23\"/> draws a\nOptions:\n(A) circle\n(B) heptagon\n(C) hexagon\n(D) kite\n(E) line\n(F) octagon\n(G) pentagon\n(H) rectangle\n(I) sector\n(J) triangle\nA: ", "answer": "(I)", "taskname": "geometric_shapes", "type": "mathematical", "response": "(A) circle"}, {"question": "Answer extremely simple questions about the colors of objects on a surface.\n\nQ: On the desk, you see the following things arranged in a row: a red fidget spinner, a gold plate, a green pencil, and a blue teddy bear. What is the color of the thing furthest from the green thing?\nOptions:\n(A) red\n(B) orange\n(C) yellow\n(D) green\n(E) blue\n(F) brown\n(G) magenta\n(H) fuchsia\n(I) mauve\n(J) teal\n(K) turquoise\n(L) burgundy\n(M) silver\n(N) gold\n(O) black\n(P) grey\n(Q) purple\n(R) pink\nA: ", "answer": "(A)", "taskname": "reasoning_about_colored_objects", "type": "complex", "response": "The thing furthest from the green thing is the blue teddy bear."}, {"question": "Distinguish deductively valid arguments from formal fallacies.\n\nQ: \"It is not always easy to grasp who is consuming which products. The following argument pertains to this question: First premise: Every loyal buyer of Dawn soap is neither an infrequent user of Redken shampoo nor a regular consumer of Proactiv soap. Therefore, whoever is none of this: a regular consumer of Proactiv soap or infrequent user of Redken shampoo, is a loyal buyer of Dawn soap.\"\nIs the argument, given the explicitly stated premises, deductively valid or invalid?\nOptions:\n- valid \n- invalid\nA: ", "answer": "invalid", "taskname": "formal_fallacies", "type": "complex", "response": "The argument is invalid because it commits a formal fallacy. The argument assumes that if someone is not using a certain product, then they must be using another product. This assumption is not necessarily true and can lead to incorrect conclusions."}, {"question": "Evaluate a random boolean function expressed as a word problem.\n\nQ: Question: Jamey lies. Sal says Jamey tells the truth. Teressa says Sal lies. Maybelle says Teressa tells the truth. Ka says Maybelle lies. Does Ka tell the truth?\nA: ", "answer": "No", "taskname": "web_of_lies", "type": "complex", "response": "Answer: Ka."}, {"question": "A task requiring determining the final numbers of objects mentioned.\n\nQ: I have a toaster, a car, and a table. How many objects do I have?\nA: ", "answer": "3", "taskname": "object_counting", "type": "complex", "response": "Three."}, {"question": "Determine which of two sentences is sarcastic.\n\nQ: Which statement is sarcastic?\nOptions:\n(A) Of course. It is not like something you do in a private setting could never be held against you in a professional matter\n(B) Of course. It is not like something you do in a private setting could ever be held against you in a professional matter\nA: ", "answer": "(B)", "taskname": "snarks", "type": "humanoid", "response": "(B) Of course. It is not like something you do in a private setting could ever be held against you in a professional matter"}, {"question": "Evaluate a random boolean function expressed as a word problem.\n\nQ: Question: Millie tells the truth. Millicent says Millie tells the truth. Raymond says Millicent tells the truth. Crista says Raymond lies. Ka says Crista tells the truth. Does Ka tell the truth?\nA: ", "answer": "No", "taskname": "web_of_lies", "type": "complex", "response": "No, Ka does not tell the truth in this scenario."}, {"question": "Task description: Answer questions about which times certain events could have occurred.\n\nQ: Today, Betty went to the coffee shop. Between what times could they have gone?\nWe know that:\nBetty woke up at 8am.\nEmily saw Betty buying a bike at the bike shop from 8am to 10am.\nSusan saw Betty walking in the garden from 10am to 12pm.\nJohn saw Betty working at the office from 1pm to 3pm.\nLisa saw Betty buying cookies at a bakery from 3pm to 4pm.\nMark saw Betty taking photos near the Eiffel Tower from 4pm to 5pm.\nThe coffee shop was closed after 5pm.\nBetween what times could Betty have gone to the coffee shop?\nOptions:\n(A) 1pm to 3pm\n(B) 8am to 10am\n(C) 10am to 12pm\n(D) 12pm to 1pm\nA: ", "answer": "(D)", "taskname": "temporal_sequences", "type": "linguistic", "response": "(A) 1pm to 3pm."}, {"question": "Distinguish deductively valid arguments from formal fallacies.\n\nQ: \"Is Fred a cousin of Robert? Is Joe related to Bob? In large families, it is sometimes difficult to keep track of all one's relatives. The following argument seeks to clarify some such relations: First, Cecil is a schoolmate of Tyler. Second, nobody is neither a schoolmate of Tyler nor a nephew of Owen. So, necessarily, Cecil is not a nephew of Owen.\"\nIs the argument, given the explicitly stated premises, deductively valid or invalid?\nOptions:\n- valid \n- invalid\nA: ", "answer": "invalid", "taskname": "formal_fallacies", "type": "complex", "response": "The argument is invalid because it commits a formal fallacy known as \"affirming the consequent.\" The second premise asserts that if someone is not a schoolmate of Tyler, then they cannot be a nephew of Owen. However, this does not necessarily mean that if someone is a nephew of Owen, then they must be a schoolmate of Tyler. Therefore, the argument's conclusion does not follow logically from its premises."}, {"question": "Detect the type of error in an English translation of a German source sentence.\n\nQ: The following translations from German to English contain a particular error. That error will be one of the following types: Named Entities: An entity (names, places, locations, etc.) is changed to a different entity. Numerical Values: Numerical values (ordinals or cardinals), dates, and/or units are changed. Modifiers or Adjectives: The modifiers and adjectives pertaining to a noun are changed. Negation or Antonyms: Introduce or remove a negation or change comparatives to their antonyms. Facts: Trivial factual errors not pertaining to the above classes are introduced in the translations. Dropped Content: A significant clause in the translation is removed. Please identify that error.  Source: Die Liste der Kinos im Berliner Bezirk Tempelhof-Sch\u00f6neberg gibt eine \u00dcbersicht aller Kinos, die im Berliner Bezirk Tempelhof-Sch\u00f6neberg existiert haben oder noch existieren.\nTranslation: The list of cinemas in Berlin's district gives an overview of all cinemas that exist or still exist in the Tempelhof-Sch\u00f6neberg district of Berlin.\nThe translation contains an error pertaining to\nOptions:\n(A) Modifiers or Adjectives\n(B) Numerical Values\n(C) Negation or Antonyms\n(D) Named Entities\n(E) Dropped Content\n(F) Facts\nA: ", "answer": "(A)", "taskname": "salient_translation_error_detection", "type": "linguistic", "response": "The error in the translation is related to the \"Named Entities\" category. The sentence mentions \"Berliner Bezirk Tempelhof-Sch\u00f6neberg\", which is a named entity in the German sentence. However, in the translation, it has been changed to \"Berlin's district\", which is not a named entity in English. This change could lead to confusion or misinterpretation of the original meaning."}, {"question": "Evaluate the result of a random Boolean expression.\n\nQ: ( True ) and False or not False is\nA: ", "answer": "True", "taskname": "boolean_expressions", "type": "complex", "response": "The result of a random Boolean expression is always either True or False."}, {"question": "Answer questions about causal attribution.\n\nQ: How would a typical person answer each of the following questions about causation?\nLong ago, when John was only 17 years old, he got a job working for a large manufacturing company. He started out working on an assembly line for minimum wage, but after a few years at the company, he was given a choice between two line manager positions. He could stay in the woodwork division, which is where he was currently working. Or he could move to the plastics division. John was unsure what to do because he liked working in the woodwork division, but he also thought it might be worth trying something different. He finally decided to switch to the plastics division and try something new. For the last 30 years, John has worked as a production line supervisor in the plastics division. After the first year there, the plastics division was moved to a different building with more space. Unfortunately, through the many years he worked there, John was exposed to asbestos, a highly carcinogenic substance. Most of the plastics division was quite safe, but the small part in which John worked was exposed to asbestos fibers. And now, although John has never smoked a cigarette in his life and otherwise lives a healthy lifestyle, he has a highly progressed and incurable case of lung cancer at the age of 50. John had seen three cancer specialists, all of whom confirmed the worst: that, except for pain, John's cancer was untreatable and he was absolutely certain to die from it very soon (the doctors estimated no more than 2 months). Yesterday, while John was in the hospital for a routine medical appointment, a new nurse accidentally administered the wrong medication to him. John was allergic to the drug and he immediately went into shock and experienced cardiac arrest (a heart attack). Doctors attempted to resuscitate him but he died minutes after the medication was administered. Did John's job cause his premature death?\nOptions:\n- Yes\n- No\nA: ", "answer": "No", "taskname": "causal_judgement", "type": "complex", "response": "As an AI language model, I cannot determine the correct answer to this question as it is too subjective and depends on personal beliefs and opinions."}, {"question": "A logical deduction task which requires deducing the order of a sequence of objects.\n\nQ: The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a shelf, there are five books: a yellow book, a brown book, a gray book, a black book, and a purple book. The yellow book is to the right of the purple book. The black book is to the left of the purple book. The black book is the third from the left. The brown book is the leftmost.\nOptions:\n(A) The yellow book is the second from the right\n(B) The brown book is the second from the right\n(C) The gray book is the second from the right\n(D) The black book is the second from the right\n(E) The purple book is the second from the right\nA: ", "answer": "(E)", "taskname": "logical_deduction_five_objects", "type": "complex", "response": "The yellow book is the second from the right."}, {"question": "Answer questions about a table of penguins and their attributes.\n\nQ: Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  We now add a penguin to the table:\nJames, 12, 90, 12\nAnd here is a similar table, but listing giraffes:\nname, age, height (cm), weight (kg)\nJody, 5, 430, 620\nGladys, 10, 420, 590\nMarian, 2, 310, 410\nDonna, 9, 440, 650\nWhich is the oldest penguin?\nOptions:\n(A) Louis\n(B) Bernard\n(C) Vincent\n(D) Gwen\n(E) James\nA: ", "answer": "(E)", "taskname": "penguins_in_a_table", "type": "complex", "response": "(E) James"}, {"question": "Given a series of navigation instructions, determine whether one would end up back at the starting point.\n\nQ: If you follow these instructions, do you return to the starting point? Always face forward. Take 5 steps left. Take 1 step backward. Take 4 steps right. Take 1 step backward. Take 8 steps left. Take 6 steps left.\nOptions:\n- Yes\n- No\nA: ", "answer": "No", "taskname": "navigate", "type": "complex", "response": "No."}, {"question": "Evaluate the result of a random Boolean expression.\n\nQ: not ( False or False and False ) is\nA: ", "answer": "True", "taskname": "boolean_expressions", "type": "complex", "response": "The result of the random Boolean expression is \"True\"."}, {"question": "Determine which of two sentences is sarcastic.\n\nQ: Which statement is sarcastic?\nOptions:\n(A) When driving, it's very helpful to keep your foot in one place you know\n(B) When driving, it's very difficult to keep your foot in one place you know\nA: ", "answer": "(B)", "taskname": "snarks", "type": "humanoid", "response": "(B) When driving, it's very difficult to keep your foot in one place you know"}, {"question": "Detect the type of error in an English translation of a German source sentence.\n\nQ: The following translations from German to English contain a particular error. That error will be one of the following types: Named Entities: An entity (names, places, locations, etc.) is changed to a different entity. Numerical Values: Numerical values (ordinals or cardinals), dates, and/or units are changed. Modifiers or Adjectives: The modifiers and adjectives pertaining to a noun are changed. Negation or Antonyms: Introduce or remove a negation or change comparatives to their antonyms. Facts: Trivial factual errors not pertaining to the above classes are introduced in the translations. Dropped Content: A significant clause in the translation is removed. Please identify that error.  Source: Halle (Saale), etwa vom Ende des 15. bis zum Ende des 17.\nTranslation: Halle, from the end of the 15th to the end of the 17th.\nThe translation contains an error pertaining to\nOptions:\n(A) Modifiers or Adjectives\n(B) Numerical Values\n(C) Negation or Antonyms\n(D) Named Entities\n(E) Dropped Content\n(F) Facts\nA: ", "answer": "(D)", "taskname": "salient_translation_error_detection", "type": "linguistic", "response": "The error in the translation is \"Numerical Values\". The correct numerical value in the source sentence is not maintained in the translation."}, {"question": "Distinguish deductively valid arguments from formal fallacies.\n\nQ: \"Here comes a perfectly valid argument: Sophie is an infrequent user of Nioxin shampoo. Every owner of a Nexxus shampoo and every infrequent user of Nioxin shampoo is a frequent consumer of Schwarzkopf shampoo. In consequence, Sophie is a frequent consumer of Schwarzkopf shampoo.\"\nIs the argument, given the explicitly stated premises, deductively valid or invalid?\nOptions:\n- valid \n- invalid\nA: ", "answer": "valid", "taskname": "formal_fallacies", "type": "complex", "response": "The argument is valid."}, {"question": "Answer extremely simple questions about the colors of objects on a surface.\n\nQ: On the nightstand, you see a set of items arranged in a row: a burgundy bracelet, a turquoise mug, a pink crayon, a silver sheet of paper, a brown plate, and a green cat toy. What is the color of the left-most item?\nOptions:\n(A) red\n(B) orange\n(C) yellow\n(D) green\n(E) blue\n(F) brown\n(G) magenta\n(H) fuchsia\n(I) mauve\n(J) teal\n(K) turquoise\n(L) burgundy\n(M) silver\n(N) gold\n(O) black\n(P) grey\n(Q) purple\n(R) pink\nA: ", "answer": "(L)", "taskname": "reasoning_about_colored_objects", "type": "complex", "response": "The left-most item is a pink crayon."}, {"question": "Determine whether an artificially constructed sentence relating to sports is plausible or not.\n\nQ: Is the following sentence plausible? \"Marcell Ozuna scored a touchdown.\"\nA: ", "answer": "no", "taskname": "sports_understanding", "type": "factual", "response": "No, it is not plausible as Marcell Ozuna is a professional baseball player and does not play football or score touchdowns."}, {"question": "A logical deduction task which requires deducing the order of a sequence of objects.\n\nQ: The following paragraphs each describe a set of seven objects arranged in a fixed order. The statements are logically consistent within each paragraph. In a golf tournament, there were seven golfers: Joe, Mel, Mya, Eve, Rob, Ada, and Dan. Rob finished first. Eve finished last. Dan finished above Ada. Mel finished above Mya. Joe finished second-to-last. Mya finished third.\nOptions:\n(A) Joe finished second\n(B) Mel finished second\n(C) Mya finished second\n(D) Eve finished second\n(E) Rob finished second\n(F) Ada finished second\n(G) Dan finished second\nA: ", "answer": "(B)", "taskname": "logical_deduction_seven_objects", "type": "complex", "response": "(G) Dan finished second."}, {"question": "Distinguish deductively valid arguments from formal fallacies.\n\nQ: \"Here comes a perfectly valid argument: To start with, being an ingredient of Eye Definer Twig is necessary for being an ingredient of FACIAL SCRUB. Now, not being an ingredient of NARS Pressed Powder is sufficient for not being an ingredient of Eye Definer Twig. Therefore, being an ingredient of NARS Pressed Powder is necessary for being an ingredient of FACIAL SCRUB.\"\nIs the argument, given the explicitly stated premises, deductively valid or invalid?\nOptions:\n- valid \n- invalid\nA: ", "answer": "valid", "taskname": "formal_fallacies", "type": "complex", "response": "The argument is valid."}, {"question": "A logical deduction task which requires deducing the order of a sequence of objects.\n\nQ: The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. A fruit stand sells five fruits: loquats, pears, watermelons, kiwis, and plums. The loquats are the third-most expensive. The loquats are more expensive than the watermelons. The plums are less expensive than the watermelons. The kiwis are more expensive than the pears.\nOptions:\n(A) The loquats are the third-most expensive\n(B) The pears are the third-most expensive\n(C) The watermelons are the third-most expensive\n(D) The kiwis are the third-most expensive\n(E) The plums are the third-most expensive\nA: ", "answer": "(A)", "taskname": "logical_deduction_five_objects", "type": "complex", "response": "The loquats are the third-most expensive."}, {"question": "Determine which of two sentences is sarcastic.\n\nQ: Which statement is sarcastic?\nOptions:\n(A) It only received the lowest gross sales for any recent action film. Yeah, no one is rewatching\n(B) It only received the highest gross sales for any recent action film. Yeah, no one is rewatching\nA: ", "answer": "(B)", "taskname": "snarks", "type": "humanoid", "response": "(A) is the sarcastic statement."}, {"question": "A logical deduction task which requires deducing the order of a sequence of objects.\n\nQ: The following paragraphs each describe a set of seven objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch, there are seven birds: an owl, a crow, a falcon, a cardinal, a hummingbird, a quail, and a hawk. The falcon is to the left of the crow. The quail is to the right of the cardinal. The hummingbird is to the right of the quail. The falcon is the second from the right. The hummingbird is to the left of the hawk. The owl is the third from the left.\nOptions:\n(A) The owl is the second from the left\n(B) The crow is the second from the left\n(C) The falcon is the second from the left\n(D) The cardinal is the second from the left\n(E) The hummingbird is the second from the left\n(F) The quail is the second from the left\n(G) The hawk is the second from the left\nA: ", "answer": "(F)", "taskname": "logical_deduction_seven_objects", "type": "complex", "response": "(A) The owl is the second from the left."}, {"question": "Detect the type of error in an English translation of a German source sentence.\n\nQ: The following translations from German to English contain a particular error. That error will be one of the following types: Named Entities: An entity (names, places, locations, etc.) is changed to a different entity. Numerical Values: Numerical values (ordinals or cardinals), dates, and/or units are changed. Modifiers or Adjectives: The modifiers and adjectives pertaining to a noun are changed. Negation or Antonyms: Introduce or remove a negation or change comparatives to their antonyms. Facts: Trivial factual errors not pertaining to the above classes are introduced in the translations. Dropped Content: A significant clause in the translation is removed. Please identify that error.  Source: Curt Adolph Netto war ein deutscher Metallurge und Autor.\nTranslation: Curt Adolph Netto was a German metalist and author.\nThe translation contains an error pertaining to\nOptions:\n(A) Modifiers or Adjectives\n(B) Numerical Values\n(C) Negation or Antonyms\n(D) Named Entities\n(E) Dropped Content\n(F) Facts\nA: ", "answer": "(F)", "taskname": "salient_translation_error_detection", "type": "linguistic", "response": "The error in the translation is \"Numerical Values\". The correct numerical value in the source sentence is \"1\" for \"ein\", which means \"one\". The translator has mistakenly changed it to \"a\" which changes the meaning of the sentence."}, {"question": "Name geometric shapes from their SVG paths.\n\nQ: This SVG path element <path d=\"M 64.00,63.00 L 44.00,63.00 L 44.00,50.00 L 64.00,50.00 L 64.00,37.00 L 85.00,57.00 L 64.00,76.00 L 64.00,63.00\"/> draws a\nOptions:\n(A) circle\n(B) heptagon\n(C) hexagon\n(D) kite\n(E) line\n(F) octagon\n(G) pentagon\n(H) rectangle\n(I) sector\n(J) triangle\nA: ", "answer": "(B)", "taskname": "geometric_shapes", "type": "mathematical", "response": "(A) circle"}, {"question": "A task requiring sorting all given words.\n\nQ: Sort the following words alphabetically: List: windowsill appoint biharmonic moustache baneberry wiry dyne pirate\nA: ", "answer": "appoint baneberry biharmonic dyne moustache pirate windowsill wiry", "taskname": "word_sorting", "type": "linguistic", "response": "Alphabetized: appoint biharmonic moustache baneberry wiry dyne pirate"}, {"question": "A task requiring determining the final positions of a set of objects given their initial positions and a description of a sequence of swaps.\n\nQ: Alice, Bob, Claire, Dave, Eve, Fred, and Gertrude are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Ophelia, Bob is dancing with Patrick, Claire is dancing with Karl, Dave is dancing with Rodrigo, Eve is dancing with Izzi, Fred is dancing with Helga, and Gertrude is dancing with Jamie.\nThroughout the song, the dancers often trade partners. First, Claire and Eve switch partners. Then, Gertrude and Alice switch partners. Then, Bob and Alice switch partners. Then, Eve and Gertrude switch partners. Then, Fred and Claire switch partners. Then, Fred and Bob switch partners. Finally, Dave and Fred switch partners. At the end of the dance, Fred is dancing with\nOptions:\n(A) Ophelia\n(B) Patrick\n(C) Karl\n(D) Rodrigo\n(E) Izzi\n(F) Helga\n(G) Jamie\nA: ", "answer": "(D)", "taskname": "tracking_shuffled_objects_seven_objects", "type": "complex", "response": "(G) Jamie"}, {"question": "Answer questions about simple arithmetic.\n\nQ: ((1 - 2 + 5 * 2) + (-2 - -7 + 3 * -8)) =\nA: ", "answer": "-10", "taskname": "multistep_arithmetic_two", "type": "mathematical", "response": "The expression cannot be simplified further."}, {"question": "Select the humorous edit that 'ruins' the input movie or musical artist name.\n\nQ: Which of the following is a humorous edit of this artist or movie name: 'dave matthews band'?\nOptions:\n(A) dave matthewg band\n(B) dave matthews hand\n(C) dave matthews xand\n(D) dave matthews basnd\nA: ", "answer": "(B)", "taskname": "ruin_names", "type": "humanoid", "response": "(A) dave matthewg band"}, {"question": "Infer the date from context.\n\nQ: Jane was born on the last day of Feburary in 2001. Today is her 16-year-old birthday. What is the date 24 hours later in MM/DD/YYYY?\nOptions:\n(A) 05/04/2017\n(B) 03/01/1919\n(C) 03/01/2017\n(D) 03/01/2005\n(E) 02/15/2017\n(F) 06/02/2017\nA: ", "answer": "(C)", "taskname": "date_understanding", "type": "linguistic", "response": "(A) 05/04/2017"}, {"question": "Evaluate a random boolean function expressed as a word problem.\n\nQ: Question: Jaymie lies. Christie says Jaymie tells the truth. Alejandro says Christie lies. Gwenn says Alejandro tells the truth. Sal says Gwenn lies. Does Sal tell the truth?\nA: ", "answer": "No", "taskname": "web_of_lies", "type": "complex", "response": "No, Sal does not tell the truth."}, {"question": "Answer extremely simple questions about the colors of objects on a surface.\n\nQ: On the table, you see a bunch of objects arranged in a row: a yellow keychain, a silver envelope, a black booklet, and a teal plate. What is the color of the right-most object?\nOptions:\n(A) red\n(B) orange\n(C) yellow\n(D) green\n(E) blue\n(F) brown\n(G) magenta\n(H) fuchsia\n(I) mauve\n(J) teal\n(K) turquoise\n(L) burgundy\n(M) silver\n(N) gold\n(O) black\n(P) grey\n(Q) purple\n(R) pink\nA: ", "answer": "(J)", "taskname": "reasoning_about_colored_objects", "type": "complex", "response": "The right-most object on the table is a teal plate."}, {"question": "Recommend movies similar to the given list of movies.\n\nQ: Find a movie similar to Apollo 13, Batman, Dances with Wolves, Braveheart:\nOptions:\n(A) Schindler's List\n(B) Crimes and Misdemeanors\n(C) King Kong\n(D) Gorillas in the Mist\nA: ", "answer": "(A)", "taskname": "movie_recommendation", "type": "humanoid", "response": "(A) Schindler's List"}, {"question": "A task requiring determining the final positions of a set of objects given their initial positions and a description of a sequence of swaps.\n\nQ: Alice, Bob, and Claire are dancers at a square dance. At the start of a song, they each have a partner: Alice is dancing with Izzi, Bob is dancing with Patrick, and Claire is dancing with Ophelia.\nThroughout the song, the dancers often trade partners. First, Bob and Alice switch partners. Then, Claire and Bob switch partners. Finally, Claire and Alice switch partners. At the end of the dance, Bob is dancing with\nOptions:\n(A) Izzi\n(B) Patrick\n(C) Ophelia\nA: ", "answer": "(C)", "taskname": "tracking_shuffled_objects_three_objects", "type": "complex", "response": "(A) Izzi"}, {"question": "Evaluate a random boolean function expressed as a word problem.\n\nQ: Question: Ryan lies. Kristian says Ryan lies. Teressa says Kristian tells the truth. Amberly says Teressa tells the truth. Jamey says Amberly tells the truth. Does Jamey tell the truth?\nA: ", "answer": "Yes", "taskname": "web_of_lies", "type": "complex", "response": "Answer: Yes."}, {"question": "Infer the date from context.\n\nQ: Today is the last day of the first quarter of 2008. What is the date a month ago in MM/DD/YYYY?\nOptions:\n(A) 02/29/2008\n(B) 02/08/2008\n(C) 12/26/2007\n(D) 02/28/2008\n(E) 02/01/2008\n(F) 08/29/2008\nA: ", "answer": "(A)", "taskname": "date_understanding", "type": "linguistic", "response": "(A) 02/29/2008"}, {"question": "Evaluate the result of a random Boolean expression.\n\nQ: ( False ) or False and not True is\nA: ", "answer": "False", "taskname": "boolean_expressions", "type": "complex", "response": "False"}, {"question": "Given a series of navigation instructions, determine whether one would end up back at the starting point.\n\nQ: If you follow these instructions, do you return to the starting point? Take 6 steps. Take 5 steps. Take 6 steps.\nOptions:\n- Yes\n- No\nA: ", "answer": "No", "taskname": "navigate", "type": "complex", "response": "Yes."}, {"question": "Answer questions about causal attribution.\n\nQ: How would a typical person answer each of the following questions about causation?\nIn a particular building there are two businesses, a travel agency and a graphic design studio. The building's climate control system is a new design that saves energy by keeping track of the number of people in the building, and only turning on when enough people have entered the building. The climate control system will turn on when the people who work at the travel agency or the people who work in the design studio arrive for work. Each office has enough employees to turn on the climate control system on their own. The travel agency employees almost always arrive at 8:45 am, and the design studio employees almost always arrive at 8:45 am. Today, the travel agency employees arrived at 8:45 am. The design studio employees also arrived at 8:45 am, as usual. So, today, the climate control system turned on at 8:45 am. Did the design studio agents cause the climate control system to turn on at 8:45 am?\nOptions:\n- Yes\n- No\nA: ", "answer": "Yes", "taskname": "causal_judgement", "type": "complex", "response": "No. The arrival of the design studio employees did not cause the climate control system to turn on at 8:45 am. The climate control system was programmed to turn on when a certain number of people entered the building, regardless of who those people were. The arrival of the travel agency employees at the same time as the design studio employees simply triggered the system's automatic activation."}, {"question": "Answer questions about a table of penguins and their attributes.\n\nQ: Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15  For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.  We then delete the penguin named Bernard from the table.\nWhich is the younest penguin?\nOptions:\n(A) Louis\n(B) Bernard\n(C) Vincent\n(D) Gwen\n(E) James\nA: ", "answer": "(A)", "taskname": "penguins_in_a_table", "type": "complex", "response": "(A) Louis"}, {"question": "A logical deduction task which requires deducing the order of a sequence of objects.\n\nQ: The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a shelf, there are five books: a white book, a green book, a brown book, a gray book, and an orange book. The gray book is to the right of the orange book. The green book is the second from the right. The brown book is to the right of the white book. The brown book is to the left of the orange book.\nOptions:\n(A) The white book is the third from the left\n(B) The green book is the third from the left\n(C) The brown book is the third from the left\n(D) The gray book is the third from the left\n(E) The orange book is the third from the left\nA: ", "answer": "(E)", "taskname": "logical_deduction_five_objects", "type": "complex", "response": "Answer: E. The orange book is the third from the left."}]